{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b4f4d05e",
   "metadata": {},
   "source": [
    "Experiment of Encryption for Brain Tumor using CKKS and BFV algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c4802210",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install tenseal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c40e4610",
   "metadata": {},
   "outputs": [],
   "source": [
    "import flwr as fl\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torchvision import datasets, transforms\n",
    "import tenseal as ts\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e6f8dfb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "DATA_DIR = r\"/home/amint/HEP/Brain Tumor MRI\"\n",
    "\n",
    "# If you're running inside WSL, use the Linux mount path instead:\n",
    "# DATA_DIR = \"/mnt/d/Ascl_Mimic_Data/Brain Tumor MRI\"\n",
    "\n",
    "train_dir = os.path.join(DATA_DIR, \"Training\")\n",
    "test_dir  = os.path.join(DATA_DIR, \"Testing\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4abd5435",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total samples: 5712\n",
      "Client 1: 1904, Client 2: 1904, Client 3: 1904\n"
     ]
    }
   ],
   "source": [
    "# Transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((64,64)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "# Load dataset\n",
    "train_dataset = datasets.ImageFolder(root=train_dir, transform=transform)\n",
    "test_dataset = datasets.ImageFolder(root=test_dir, transform=transform)\n",
    "\n",
    "# Split training data into 3 clients\n",
    "total_size = len(train_dataset)\n",
    "client_size = total_size // 3\n",
    "client_datasets = random_split(train_dataset, [client_size, client_size, total_size - 2*client_size])\n",
    "\n",
    "print(f\"Total samples: {total_size}\")\n",
    "print(f\"Client 1: {len(client_datasets[0])}, Client 2: {len(client_datasets[1])}, Client 3: {len(client_datasets[2])}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6923c2d",
   "metadata": {},
   "source": [
    "Define CNN model before starting the training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d743bcc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BrainTumorCNN(nn.Module):\n",
    "    def __init__(self, num_classes=4):\n",
    "        super(BrainTumorCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, 3, padding=1)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 3, padding=1)\n",
    "        self.fc1 = nn.Linear(64*16*16, 128)\n",
    "        self.fc2 = nn.Linear(128, num_classes)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))  # (32,32,32)\n",
    "        x = self.pool(F.relu(self.conv2(x)))  # (64,16,16)\n",
    "        x = x.view(-1, 64*16*16)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63f44894",
   "metadata": {},
   "source": [
    "Create Homomorphic Encryption Contexts (CKKS & BFV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a08619ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CKKS (supports floats, good for NN weights)\n",
    "ckks_context = ts.context(ts.SCHEME_TYPE.CKKS, poly_modulus_degree=8192, coeff_mod_bit_sizes=[60, 40, 40, 60])\n",
    "ckks_context.global_scale = 2**40\n",
    "ckks_context.generate_galois_keys()\n",
    "\n",
    "# BFV (supports integers)\n",
    "bfv_context = ts.context(ts.SCHEME_TYPE.BFV, poly_modulus_degree=8192, plain_modulus=1032193)\n",
    "bfv_context.generate_galois_keys()\n",
    "bfv_context.generate_relin_keys()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52cd5dae",
   "metadata": {},
   "source": [
    "##Federated Client Definition\n",
    "\n",
    "###Clients train locally, encrypt model updates, and send to the server."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e021fb1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FLClient(fl.client.NumPyClient):\n",
    "    def __init__(self, model, train_data, test_data, encryption_scheme=\"ckks\"):\n",
    "        self.model = model\n",
    "        self.train_loader = DataLoader(train_data, batch_size=32, shuffle=True)\n",
    "        self.test_loader = DataLoader(test_data, batch_size=32)\n",
    "        self.encryption_scheme = encryption_scheme\n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "        self.optimizer = optim.Adam(self.model.parameters(), lr=0.001)\n",
    "\n",
    "    def get_parameters(self, config):\n",
    "        params = [val.cpu().numpy() for val in self.model.state_dict().values()]\n",
    "        # Encrypt parameters\n",
    "        if self.encryption_scheme == \"ckks\":\n",
    "            return [ts.ckks_vector(ckks_context, p.flatten().tolist()).serialize() for p in params]\n",
    "        else:  # BFV\n",
    "            return [ts.bfv_vector(bfv_context, p.flatten().astype(int).tolist()).serialize() for p in params]\n",
    "\n",
    "    def set_parameters(self, parameters):\n",
    "        state_dict = self.model.state_dict()\n",
    "        new_state_dict = {}\n",
    "        for (k, v), param in zip(state_dict.items(), parameters):\n",
    "            arr = np.array(param).reshape(v.shape)\n",
    "            new_state_dict[k] = torch.tensor(arr, dtype=v.dtype)\n",
    "        self.model.load_state_dict(new_state_dict, strict=True)\n",
    "\n",
    "    def fit(self, parameters, config):\n",
    "        self.set_parameters(parameters)\n",
    "        self.model.train()\n",
    "        for epoch in range(1):  # 1 epoch per round\n",
    "            for data, target in self.train_loader:\n",
    "                self.optimizer.zero_grad()\n",
    "                output = self.model(data)\n",
    "                loss = self.criterion(output, target)\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "        return self.get_parameters(config={}), len(self.train_loader.dataset), {}\n",
    "\n",
    "    def evaluate(self, parameters, config):\n",
    "        self.set_parameters(parameters)\n",
    "        self.model.eval()\n",
    "        loss, correct = 0, 0\n",
    "        with torch.no_grad():\n",
    "            for data, target in self.test_loader:\n",
    "                output = self.model(data)\n",
    "                loss += self.criterion(output, target).item()\n",
    "                pred = output.argmax(dim=1, keepdim=True)\n",
    "                correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "        accuracy = correct / len(self.test_loader.dataset)\n",
    "        return float(loss), len(self.test_loader.dataset), {\"accuracy\": accuracy}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fd5f647",
   "metadata": {},
   "source": [
    "Server Strategy with Decryption and Aggregation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2a6da87b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncryptedFedAvg(fl.server.strategy.FedAvg):\n",
    "    def __init__(self, encryption_scheme=\"ckks\"):\n",
    "        super().__init__()\n",
    "        self.encryption_scheme = encryption_scheme\n",
    "\n",
    "    def aggregate_fit(self, rnd, results, failures):\n",
    "        aggregated = []\n",
    "        for serialized_params, num_examples, _ in results:\n",
    "            if self.encryption_scheme == \"ckks\":\n",
    "                decrypted_params = [ts.ckks_vector_from(ckks_context, p).decrypt() for p in serialized_params]\n",
    "            else:\n",
    "                decrypted_params = [ts.bfv_vector_from(bfv_context, p).decrypt() for p in serialized_params]\n",
    "            aggregated.append((decrypted_params, num_examples))\n",
    "        # Standard FedAvg aggregation\n",
    "        return super().aggregate_fit(rnd, results, failures)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b801a543",
   "metadata": {},
   "source": [
    "Run Federated Learning Simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3a0ac713",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Partition test dataset equally among clients\n",
    "# test_size = len(test_dataset) // 3\n",
    "# test_clients = random_split(test_dataset, [test_size, test_size, len(test_dataset) - 2*test_size])\n",
    "\n",
    "# def client_fn(cid: str):\n",
    "#     model = BrainTumorCNN()\n",
    "#     return FLClient(model, client_datasets[int(cid)], test_clients[int(cid)], encryption_scheme=\"ckks\")\n",
    "\n",
    "# # Run Flower simulation\n",
    "# strategy = EncryptedFedAvg(encryption_scheme=\"ckks\")\n",
    "\n",
    "# fl.simulation.start_simulation(\n",
    "#     client_fn=client_fn,\n",
    "#     num_clients=3,\n",
    "#     config=fl.server.ServerConfig(num_rounds=5),\n",
    "#     strategy=strategy,\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c27f9c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7892d303",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1148fad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "42ea12bb",
   "metadata": {},
   "source": [
    "Simulation without Flower"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "922d17bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torchvision import datasets, transforms\n",
    "import tenseal as ts\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import classification_report\n",
    "import time\n",
    "import os\n",
    "DATA_DIR = r\"/home/amint/HEP/Brain Tumor MRI\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "750cee47",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = os.path.join(DATA_DIR, \"Training\")\n",
    "test_dir  = os.path.join(DATA_DIR, \"Testing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "83b05df7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total samples: 5712\n",
      "Client 1: 1904, Client 2: 1904, Client 3: 1904\n"
     ]
    }
   ],
   "source": [
    "# Image preprocessing\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((64,64)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "# Load dataset (adjust path to your dataset)\n",
    "train_dataset = datasets.ImageFolder(root=train_dir, transform=transform)\n",
    "test_dataset = datasets.ImageFolder(root=test_dir, transform=transform)\n",
    "\n",
    "# Split into 3 clients\n",
    "total_size = len(train_dataset)\n",
    "client_size = total_size // 3\n",
    "client_datasets = random_split(train_dataset, [client_size, client_size, total_size - 2*client_size])\n",
    "\n",
    "print(f\"Total samples: {total_size}\")\n",
    "print(f\"Client 1: {len(client_datasets[0])}, Client 2: {len(client_datasets[1])}, Client 3: {len(client_datasets[2])}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd2c11af",
   "metadata": {},
   "source": [
    "Define the CNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "53be2e6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BrainTumorCNN(nn.Module):\n",
    "    def __init__(self, num_classes=4):\n",
    "        super(BrainTumorCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, 3, padding=1)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 3, padding=1)\n",
    "        self.fc1 = nn.Linear(64*16*16, 128)\n",
    "        self.fc2 = nn.Linear(128, num_classes)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))  # (32,32,32)\n",
    "        x = self.pool(F.relu(self.conv2(x)))  # (64,16,16)\n",
    "        x = x.view(-1, 64*16*16)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "353af312",
   "metadata": {},
   "source": [
    "Create Homomorphic Encryption context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a1687f7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CKKS context (for floats, good for CNN weights)\n",
    "ckks_context = ts.context(ts.SCHEME_TYPE.CKKS, poly_modulus_degree=8192,\n",
    "                          coeff_mod_bit_sizes=[60, 40, 40, 60])\n",
    "ckks_context.global_scale = 2**40\n",
    "ckks_context.generate_galois_keys()\n",
    "\n",
    "# BFV context (for integers)\n",
    "bfv_context = ts.context(ts.SCHEME_TYPE.BFV, poly_modulus_degree=8192, plain_modulus=1032193)\n",
    "bfv_context.generate_galois_keys()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df9aa3d9",
   "metadata": {},
   "source": [
    "Local Traininig Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f8fadca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_local(model, dataset, epochs=10, lr=0.001):\n",
    "    loader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    model.train()\n",
    "    for _ in range(epochs):\n",
    "        for data, target in loader:\n",
    "            optimizer.zero_grad()\n",
    "            output = model(data)\n",
    "            loss = criterion(output, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7154b6bd",
   "metadata": {},
   "source": [
    "Encrypt Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "eecec41f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encrypt_parameters(params, scheme=\"ckks\"):\n",
    "    encrypted = []\n",
    "    for p in params:\n",
    "        flat = p.flatten()\n",
    "        if scheme == \"ckks\":\n",
    "            encrypted.append(ts.ckks_vector(ckks_context, flat).serialize())\n",
    "        else:\n",
    "            encrypted.append(ts.bfv_vector(bfv_context, flat.astype(int)).serialize())\n",
    "    return encrypted\n",
    "\n",
    "def decrypt_parameters(encrypted, shapes, scheme=\"ckks\"):\n",
    "    decrypted = []\n",
    "    for enc, shape in zip(encrypted, shapes):\n",
    "        if scheme == \"ckks\":\n",
    "            dec = ts.ckks_vector_from(ckks_context, enc).decrypt()\n",
    "        else:\n",
    "            dec = ts.bfv_vector_from(bfv_context, enc).decrypt()\n",
    "        decrypted.append(np.array(dec).reshape(shape))\n",
    "    return decrypted\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d04504c6",
   "metadata": {},
   "source": [
    "Federated Averaging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8e5f96d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def federated_averaging(encrypted_updates, shapes, scheme=\"ckks\"):\n",
    "    num_clients = len(encrypted_updates)\n",
    "    \n",
    "    # Decrypt all client updates\n",
    "    all_updates = []\n",
    "    for update in encrypted_updates:\n",
    "        dec_params = decrypt_parameters(update, shapes, scheme)\n",
    "        all_updates.append(dec_params)\n",
    "    \n",
    "    # Average parameters\n",
    "    avg_params = []\n",
    "    for i in range(len(all_updates[0])):\n",
    "        stacked = np.stack([client[i] for client in all_updates])\n",
    "        avg_params.append(np.mean(stacked, axis=0))\n",
    "    \n",
    "    return avg_params\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0a6f8e2",
   "metadata": {},
   "source": [
    "Run Mannual Federated Learning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f8f36d35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Federated Round 1 ---\n",
      "WARNING: The input does not fit in a single ciphertext, and some operations will be disabled.\n",
      "The following operations are disabled in this setup: matmul, matmul_plain, enc_matmul_plain, conv2d_im2col.\n",
      "If you need to use those operations, try increasing the poly_modulus parameter, to fit your input.\n",
      "WARNING: The input does not fit in a single ciphertext, and some operations will be disabled.\n",
      "The following operations are disabled in this setup: matmul, matmul_plain, enc_matmul_plain, conv2d_im2col.\n",
      "If you need to use those operations, try increasing the poly_modulus parameter, to fit your input.\n",
      "WARNING: The input does not fit in a single ciphertext, and some operations will be disabled.\n",
      "The following operations are disabled in this setup: matmul, matmul_plain, enc_matmul_plain, conv2d_im2col.\n",
      "If you need to use those operations, try increasing the poly_modulus parameter, to fit your input.\n",
      "WARNING: The input does not fit in a single ciphertext, and some operations will be disabled.\n",
      "The following operations are disabled in this setup: matmul, matmul_plain, enc_matmul_plain, conv2d_im2col.\n",
      "If you need to use those operations, try increasing the poly_modulus parameter, to fit your input.\n",
      "WARNING: The input does not fit in a single ciphertext, and some operations will be disabled.\n",
      "The following operations are disabled in this setup: matmul, matmul_plain, enc_matmul_plain, conv2d_im2col.\n",
      "If you need to use those operations, try increasing the poly_modulus parameter, to fit your input.\n",
      "WARNING: The input does not fit in a single ciphertext, and some operations will be disabled.\n",
      "The following operations are disabled in this setup: matmul, matmul_plain, enc_matmul_plain, conv2d_im2col.\n",
      "If you need to use those operations, try increasing the poly_modulus parameter, to fit your input.\n",
      "Round 1 completed.\n",
      "\n",
      "--- Federated Round 2 ---\n",
      "WARNING: The input does not fit in a single ciphertext, and some operations will be disabled.\n",
      "The following operations are disabled in this setup: matmul, matmul_plain, enc_matmul_plain, conv2d_im2col.\n",
      "If you need to use those operations, try increasing the poly_modulus parameter, to fit your input.\n",
      "WARNING: The input does not fit in a single ciphertext, and some operations will be disabled.\n",
      "The following operations are disabled in this setup: matmul, matmul_plain, enc_matmul_plain, conv2d_im2col.\n",
      "If you need to use those operations, try increasing the poly_modulus parameter, to fit your input.\n",
      "WARNING: The input does not fit in a single ciphertext, and some operations will be disabled.\n",
      "The following operations are disabled in this setup: matmul, matmul_plain, enc_matmul_plain, conv2d_im2col.\n",
      "If you need to use those operations, try increasing the poly_modulus parameter, to fit your input.\n",
      "WARNING: The input does not fit in a single ciphertext, and some operations will be disabled.\n",
      "The following operations are disabled in this setup: matmul, matmul_plain, enc_matmul_plain, conv2d_im2col.\n",
      "If you need to use those operations, try increasing the poly_modulus parameter, to fit your input.\n",
      "WARNING: The input does not fit in a single ciphertext, and some operations will be disabled.\n",
      "The following operations are disabled in this setup: matmul, matmul_plain, enc_matmul_plain, conv2d_im2col.\n",
      "If you need to use those operations, try increasing the poly_modulus parameter, to fit your input.\n",
      "WARNING: The input does not fit in a single ciphertext, and some operations will be disabled.\n",
      "The following operations are disabled in this setup: matmul, matmul_plain, enc_matmul_plain, conv2d_im2col.\n",
      "If you need to use those operations, try increasing the poly_modulus parameter, to fit your input.\n",
      "Round 2 completed.\n",
      "\n",
      "--- Federated Round 3 ---\n",
      "WARNING: The input does not fit in a single ciphertext, and some operations will be disabled.\n",
      "The following operations are disabled in this setup: matmul, matmul_plain, enc_matmul_plain, conv2d_im2col.\n",
      "If you need to use those operations, try increasing the poly_modulus parameter, to fit your input.\n",
      "WARNING: The input does not fit in a single ciphertext, and some operations will be disabled.\n",
      "The following operations are disabled in this setup: matmul, matmul_plain, enc_matmul_plain, conv2d_im2col.\n",
      "If you need to use those operations, try increasing the poly_modulus parameter, to fit your input.\n",
      "WARNING: The input does not fit in a single ciphertext, and some operations will be disabled.\n",
      "The following operations are disabled in this setup: matmul, matmul_plain, enc_matmul_plain, conv2d_im2col.\n",
      "If you need to use those operations, try increasing the poly_modulus parameter, to fit your input.\n",
      "WARNING: The input does not fit in a single ciphertext, and some operations will be disabled.\n",
      "The following operations are disabled in this setup: matmul, matmul_plain, enc_matmul_plain, conv2d_im2col.\n",
      "If you need to use those operations, try increasing the poly_modulus parameter, to fit your input.\n",
      "WARNING: The input does not fit in a single ciphertext, and some operations will be disabled.\n",
      "The following operations are disabled in this setup: matmul, matmul_plain, enc_matmul_plain, conv2d_im2col.\n",
      "If you need to use those operations, try increasing the poly_modulus parameter, to fit your input.\n",
      "WARNING: The input does not fit in a single ciphertext, and some operations will be disabled.\n",
      "The following operations are disabled in this setup: matmul, matmul_plain, enc_matmul_plain, conv2d_im2col.\n",
      "If you need to use those operations, try increasing the poly_modulus parameter, to fit your input.\n",
      "Round 3 completed.\n",
      "\n",
      "--- Federated Round 4 ---\n",
      "WARNING: The input does not fit in a single ciphertext, and some operations will be disabled.\n",
      "The following operations are disabled in this setup: matmul, matmul_plain, enc_matmul_plain, conv2d_im2col.\n",
      "If you need to use those operations, try increasing the poly_modulus parameter, to fit your input.\n",
      "WARNING: The input does not fit in a single ciphertext, and some operations will be disabled.\n",
      "The following operations are disabled in this setup: matmul, matmul_plain, enc_matmul_plain, conv2d_im2col.\n",
      "If you need to use those operations, try increasing the poly_modulus parameter, to fit your input.\n",
      "WARNING: The input does not fit in a single ciphertext, and some operations will be disabled.\n",
      "The following operations are disabled in this setup: matmul, matmul_plain, enc_matmul_plain, conv2d_im2col.\n",
      "If you need to use those operations, try increasing the poly_modulus parameter, to fit your input.\n",
      "WARNING: The input does not fit in a single ciphertext, and some operations will be disabled.\n",
      "The following operations are disabled in this setup: matmul, matmul_plain, enc_matmul_plain, conv2d_im2col.\n",
      "If you need to use those operations, try increasing the poly_modulus parameter, to fit your input.\n",
      "WARNING: The input does not fit in a single ciphertext, and some operations will be disabled.\n",
      "The following operations are disabled in this setup: matmul, matmul_plain, enc_matmul_plain, conv2d_im2col.\n",
      "If you need to use those operations, try increasing the poly_modulus parameter, to fit your input.\n",
      "WARNING: The input does not fit in a single ciphertext, and some operations will be disabled.\n",
      "The following operations are disabled in this setup: matmul, matmul_plain, enc_matmul_plain, conv2d_im2col.\n",
      "If you need to use those operations, try increasing the poly_modulus parameter, to fit your input.\n",
      "Round 4 completed.\n",
      "\n",
      "--- Federated Round 5 ---\n",
      "WARNING: The input does not fit in a single ciphertext, and some operations will be disabled.\n",
      "The following operations are disabled in this setup: matmul, matmul_plain, enc_matmul_plain, conv2d_im2col.\n",
      "If you need to use those operations, try increasing the poly_modulus parameter, to fit your input.\n",
      "WARNING: The input does not fit in a single ciphertext, and some operations will be disabled.\n",
      "The following operations are disabled in this setup: matmul, matmul_plain, enc_matmul_plain, conv2d_im2col.\n",
      "If you need to use those operations, try increasing the poly_modulus parameter, to fit your input.\n",
      "WARNING: The input does not fit in a single ciphertext, and some operations will be disabled.\n",
      "The following operations are disabled in this setup: matmul, matmul_plain, enc_matmul_plain, conv2d_im2col.\n",
      "If you need to use those operations, try increasing the poly_modulus parameter, to fit your input.\n",
      "WARNING: The input does not fit in a single ciphertext, and some operations will be disabled.\n",
      "The following operations are disabled in this setup: matmul, matmul_plain, enc_matmul_plain, conv2d_im2col.\n",
      "If you need to use those operations, try increasing the poly_modulus parameter, to fit your input.\n",
      "WARNING: The input does not fit in a single ciphertext, and some operations will be disabled.\n",
      "The following operations are disabled in this setup: matmul, matmul_plain, enc_matmul_plain, conv2d_im2col.\n",
      "If you need to use those operations, try increasing the poly_modulus parameter, to fit your input.\n",
      "WARNING: The input does not fit in a single ciphertext, and some operations will be disabled.\n",
      "The following operations are disabled in this setup: matmul, matmul_plain, enc_matmul_plain, conv2d_im2col.\n",
      "If you need to use those operations, try increasing the poly_modulus parameter, to fit your input.\n",
      "Round 5 completed.\n",
      "\n",
      "Total training time: 673.34 seconds\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "# Initialize global model\n",
    "global_model = BrainTumorCNN()\n",
    "shapes = [p.shape for p in global_model.state_dict().values()]\n",
    "\n",
    "# Convert model params to numpy\n",
    "def get_model_params(model):\n",
    "    return [val.detach().cpu().numpy() for val in model.state_dict().values()]\n",
    "\n",
    "def set_model_params(model, params):\n",
    "    state_dict = model.state_dict()\n",
    "    new_state_dict = {}\n",
    "    for (k, v), p in zip(state_dict.items(), params):\n",
    "        new_state_dict[k] = torch.tensor(p, dtype=v.dtype)\n",
    "    model.load_state_dict(new_state_dict, strict=True)\n",
    "\n",
    "# Run federated rounds\n",
    "num_rounds = 5\n",
    "scheme = \"ckks\"  # or \"bfv\"\n",
    "\n",
    "for rnd in range(1, num_rounds+1):\n",
    "    print(f\"\\n--- Federated Round {rnd} ---\")\n",
    "    client_updates = []\n",
    "    \n",
    "    for cid, dataset in enumerate(client_datasets):\n",
    "        local_model = BrainTumorCNN()\n",
    "        set_model_params(local_model, get_model_params(global_model))\n",
    "        \n",
    "        # Train locally\n",
    "        local_model = train_local(local_model, dataset, epochs=10, lr=0.01)\n",
    "        \n",
    "        # Encrypt update\n",
    "        params = get_model_params(local_model)\n",
    "        encrypted = encrypt_parameters(params, scheme=scheme)\n",
    "        client_updates.append(encrypted)\n",
    "    \n",
    "    # Aggregate on server\n",
    "    avg_params = federated_averaging(client_updates, shapes, scheme=scheme)\n",
    "    set_model_params(global_model, avg_params)\n",
    "    \n",
    "    print(f\"Round {rnd} completed.\")\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "print(f\"\\nTotal training time: {elapsed_time:.2f} seconds\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "50200e56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.4835, Accuracy: 0.8108\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.59      0.72       300\n",
      "           1       0.65      0.69      0.67       306\n",
      "           2       0.87      0.95      0.91       405\n",
      "           3       0.83      0.97      0.90       300\n",
      "\n",
      "    accuracy                           0.81      1311\n",
      "   macro avg       0.81      0.80      0.80      1311\n",
      "weighted avg       0.82      0.81      0.81      1311\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_loader = DataLoader(test_dataset, batch_size=32)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "global_model.eval()\n",
    "loss, correct = 0, 0\n",
    "all_preds, all_targets = [], []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data, target in test_loader:\n",
    "        output = global_model(data)\n",
    "        loss += criterion(output, target).item()\n",
    "        preds = output.argmax(dim=1)\n",
    "        all_preds.extend(preds.cpu().numpy())\n",
    "        all_targets.extend(target.cpu().numpy())\n",
    "        correct += preds.eq(target).sum().item()\n",
    "\n",
    "accuracy = correct / len(test_loader.dataset)\n",
    "print(f\"Test Loss: {loss/len(test_loader):.4f}, Accuracy: {accuracy:.4f}\")\n",
    "print(\"\\nClassification Report:\\n\", classification_report(all_targets, all_preds))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86134f14",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
